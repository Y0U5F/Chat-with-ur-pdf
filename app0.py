import streamlit as st
from pdf2image import convert_from_path
import base64
from mistralai import Mistral
from pydantic import BaseModel
from enum import Enum
import pycountry
import json
from pathlib import Path
from mistralai.models import ImageURLChunk, TextChunk
from tenacity import retry, stop_after_attempt, wait_exponential
import asyncio
import aiohttp

# Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ø¬Ù‡Ø© Streamlit
st.title("Chat with Your PDF ğŸ“„")
st.write("Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF ÙˆØ§Ø³Ø£Ù„ Ø£ÙŠ Ø³Ø¤Ø§Ù„ Ø¹Ù† Ù…Ø­ØªÙˆØ§Ù‡ØŒ ÙˆÙ‡Ù†Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù†ØµÙˆØµ ÙˆÙ†Ø¬Ø§ÙˆØ¨Ùƒ!")

# Ø¥Ø¹Ø¯Ø§Ø¯ Mistral Client
# Ø¹Ù„Ù‰ Streamlit CloudØŒ Ø§Ù„Ù€ API Key Ù„Ø§Ø²Ù… ÙŠÙƒÙˆÙ† ÙÙŠ Secrets
api_key = st.secrets["MISTRAL_API_KEY"]
client = Mistral(api_key=api_key)

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù„ØºØ§Øª Ø¹Ø´Ø§Ù† Ù†Ø¯Ø¹Ù… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ù„ØºØ§Øª Ù…Ø®ØªÙ„ÙØ©
languages = {lang.alpha_2: lang.name for lang in pycountry.languages if hasattr(lang, 'alpha_2')}

class LanguageMeta(Enum.__class__):
    def __new__(metacls, cls, bases, classdict):
        for code, name in languages.items():
            classdict[name.upper().replace(' ', '_')] = name
        return super().__new__(metacls, cls, bases, classdict)

class Language(Enum, metaclass=LanguageMeta):
    pass

# ØªØ¹Ø±ÙŠÙ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Mistral OCR
class StructuredOCR(BaseModel):
    file_name: str
    topics: list[str]
    languages: list[Language]
    ocr_contents: dict

# Ø¯Ø§Ù„Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ØµÙˆØ±Ø© Ø¨Ù€ OCR Ù…Ø¹ Retry
@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
async def structured_ocr_async(image_path: str, session: aiohttp.ClientSession) -> StructuredOCR:
    image_file = Path(image_path)
    assert image_file.is_file(), "Ø§Ù„Ù…Ù„Ù Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯! Ø§ØªØ£ÙƒØ¯ Ø¥Ù† Ø§Ù„ØµÙˆØ±Ø© Ù…ÙˆØ¬ÙˆØ¯Ø©."

    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù€ base64
    encoded_image = base64.b64encode(image_file.read_bytes()).decode()
    base64_data_url = f"data:image/jpeg;base64,{encoded_image}"

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù€ OCR
    image_response = client.ocr.process(document=ImageURLChunk(image_url=base64_data_url), model="mistral-ocr-latest")
    image_ocr_markdown = image_response.pages[0].markdown

    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ù„Ù€ JSON
    chat_response = client.chat.parse(
        model="pixtral-12b-latest",
        messages=[
            {
                "role": "user",
                "content": [
                    ImageURLChunk(image_url=base64_data_url),
                    TextChunk(text=(
                        "Ø¯Ù‡ Ù†Øµ Ø§Ù„Ù€ OCR Ø¨Ø§Ù„Ù…Ø§Ø±ÙƒØ¯Ø§ÙˆÙ†:\n"
                        f"<BEGIN_IMAGE_OCR>\n{image_ocr_markdown}\n<END_IMAGE_OCR>.\n"
                        "Ø­ÙˆÙ‘Ù„ Ø§Ù„Ù†Øµ Ø¯Ù‡ Ù„Ù€ JSON Ù…Ù†Ø¸Ù…."
                    ))
                ],
            },
        ],
        response_format=StructuredOCR,
        temperature=0
    )
    return chat_response.choices[0].message.parsed

# Ø¯Ø§Ù„Ø© Ù„ØªØ­ÙˆÙŠÙ„ PDF Ù„ØµÙˆØ± ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†
async def process_pdf_async(pdf_file):
    # Ø­ÙØ¸ Ø§Ù„Ù€ PDF Ù…Ø¤Ù‚ØªÙ‹Ø§
    with open("temp.pdf", "wb") as f:
        f.write(pdf_file.read())
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù€ PDF Ù„ØµÙˆØ± Ù…Ø¹ DPI Ø£Ù‚Ù„ Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù…
    # Ù…Ù„Ø§Ø­Ø¸Ø©: poppler-utils Ø¨ÙŠØªØ«Ø¨Ù‘Øª Ø¹Ù† Ø·Ø±ÙŠÙ‚ Dockerfile Ø£Ùˆ .streamlit/packages.txt
    images = convert_from_path("temp.pdf", dpi=100, first_page=1, last_page=10)  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 10 ØµÙØ­Ø§Øª
    extracted_texts = []

    async with aiohttp.ClientSession() as session:
        tasks = []
        for i, image in enumerate(images):
            image_path = f"page_{i}.jpg"
            image.save(image_path, "JPEG")
            tasks.append(structured_ocr_async(image_path, session))
        
        # Ø¬Ù…Ø¹ Ø§Ù„Ù†ØªØ§ÙŠØ¬ Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for result in results:
            if isinstance(result, StructuredOCR):
                extracted_texts.append(result.ocr_contents)
            else:
                st.warning(f"ÙØ´Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© ØµÙØ­Ø©: {result}")
    
    return extracted_texts

# Ø¯Ø§Ù„Ø© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø©
def ask_question(question: str, extracted_texts: list) -> str:
    context = "\n".join([str(text) for text in extracted_texts])
    response = client.chat.complete(
        model="pixtral-12b-latest",
        messages=[
            {
                "role": "user",
                "content": f"Ø§Ù„Ø³ÙŠØ§Ù‚: {context}\n\nØ§Ù„Ø³Ø¤Ø§Ù„: {question}\n\nØ¬Ø§ÙˆØ¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚."
            }
        ],
        temperature=0.7
    )
    return response.choices[0].message.content

# ÙˆØ§Ø¬Ù‡Ø© Streamlit
uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF Ù‡Ù†Ø§", type="pdf")
if uploaded_file:
    st.write("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù... â³")
    try:
        extracted_texts = asyncio.run(process_pdf_async(uploaded_file))
        st.session_state["extracted_texts"] = extracted_texts
        st.success("ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ù†Ø¬Ø§Ø­! âœ…")
        st.write("Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©:")
        st.json(extracted_texts)
    except Exception as e:
        st.error(f"Ø­ØµÙ„ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {e}")

question = st.text_input("Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„ Ø¹Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù€ PDF:")
if question and "extracted_texts" in st.session_state:
    try:
        answer = ask_question(question, st.session_state["extracted_texts"])
        st.write("Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:")
        st.write(answer)
    except Exception as e:
        st.error(f"Ø­ØµÙ„ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: {e}")
